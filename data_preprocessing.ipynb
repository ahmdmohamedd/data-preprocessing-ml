{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e18fb3c4-3ad5-43c6-b8de-4aaa6ee7ad32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 729322 entries, 0 to 729321\n",
      "Data columns (total 11 columns):\n",
      " #   Column              Non-Null Count   Dtype  \n",
      "---  ------              --------------   -----  \n",
      " 0   id                  729322 non-null  object \n",
      " 1   vendor_id           729322 non-null  int64  \n",
      " 2   pickup_datetime     729322 non-null  object \n",
      " 3   dropoff_datetime    729322 non-null  object \n",
      " 4   passenger_count     729322 non-null  int64  \n",
      " 5   pickup_longitude    729322 non-null  float64\n",
      " 6   pickup_latitude     729322 non-null  float64\n",
      " 7   dropoff_longitude   729322 non-null  float64\n",
      " 8   dropoff_latitude    729322 non-null  float64\n",
      " 9   store_and_fwd_flag  729322 non-null  object \n",
      " 10  trip_duration       729322 non-null  int64  \n",
      "dtypes: float64(4), int64(3), object(4)\n",
      "memory usage: 61.2+ MB\n",
      "None\n",
      "           vendor_id  passenger_count  pickup_longitude  pickup_latitude  \\\n",
      "count  729322.000000    729322.000000     729322.000000    729322.000000   \n",
      "mean        1.535403         1.662055        -73.973513        40.750919   \n",
      "std         0.498745         1.312446          0.069754         0.033594   \n",
      "min         1.000000         0.000000       -121.933342        34.712234   \n",
      "25%         1.000000         1.000000        -73.991859        40.737335   \n",
      "50%         2.000000         1.000000        -73.981758        40.754070   \n",
      "75%         2.000000         2.000000        -73.967361        40.768314   \n",
      "max         2.000000         9.000000        -65.897385        51.881084   \n",
      "\n",
      "       dropoff_longitude  dropoff_latitude  trip_duration  \n",
      "count      729322.000000     729322.000000   7.293220e+05  \n",
      "mean          -73.973422         40.751775   9.522291e+02  \n",
      "std             0.069588          0.036037   3.864626e+03  \n",
      "min          -121.933304         32.181141   1.000000e+00  \n",
      "25%           -73.991318         40.735931   3.970000e+02  \n",
      "50%           -73.979759         40.754509   6.630000e+02  \n",
      "75%           -73.963036         40.769741   1.075000e+03  \n",
      "max           -65.897385         43.921028   1.939736e+06  \n",
      "Missing Values:\n",
      " id                    0\n",
      "vendor_id             0\n",
      "pickup_datetime       0\n",
      "dropoff_datetime      0\n",
      "passenger_count       0\n",
      "pickup_longitude      0\n",
      "pickup_latitude       0\n",
      "dropoff_longitude     0\n",
      "dropoff_latitude      0\n",
      "store_and_fwd_flag    0\n",
      "trip_duration         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load dataset\n",
    "file_path = \"nyc_taxi_trip_duration.csv\"\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Display dataset information\n",
    "print(data.info())\n",
    "print(data.describe())\n",
    "\n",
    "# Check for missing values\n",
    "missing = data.isnull().sum()\n",
    "print(\"Missing Values:\\n\", missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f62c1bc3-1bdc-4faa-83d3-a2d2558162bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned data shape: (692359, 11)\n"
     ]
    }
   ],
   "source": [
    "# Handle missing values (drop or impute)\n",
    "data = data.dropna()\n",
    "\n",
    "# Remove outliers in trip duration\n",
    "q1 = data['trip_duration'].quantile(0.25)\n",
    "q3 = data['trip_duration'].quantile(0.75)\n",
    "iqr = q3 - q1\n",
    "lower_bound = q1 - 1.5 * iqr\n",
    "upper_bound = q3 + 1.5 * iqr\n",
    "data = data[(data['trip_duration'] >= lower_bound) & (data['trip_duration'] <= upper_bound)]\n",
    "\n",
    "# Check for duplicates\n",
    "data = data.drop_duplicates()\n",
    "\n",
    "print(\"Cleaned data shape:\", data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86ac556f-bf52-4e68-9774-9ab166eb28dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from geopy.distance import geodesic\n",
    "\n",
    "# Calculate distance between pickup and dropoff points\n",
    "def haversine_distance(row):\n",
    "    start = (row['pickup_latitude'], row['pickup_longitude'])\n",
    "    end = (row['dropoff_latitude'], row['dropoff_longitude'])\n",
    "    return geodesic(start, end).km\n",
    "\n",
    "data['distance'] = data.apply(haversine_distance, axis=1)\n",
    "\n",
    "# Extract temporal features\n",
    "data['pickup_datetime'] = pd.to_datetime(data['pickup_datetime'])\n",
    "data['hour'] = data['pickup_datetime'].dt.hour\n",
    "data['day'] = data['pickup_datetime'].dt.day\n",
    "data['month'] = data['pickup_datetime'].dt.month\n",
    "\n",
    "# One-hot encoding for categorical variables\n",
    "data = pd.get_dummies(data, columns=['vendor_id', 'store_and_fwd_flag'], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f50d3f17-8465-45ca-9573-ea0fb0593ca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (553887, 10)\n",
      "Testing set shape: (138472, 10)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Remove non-feature columns (like IDs or timestamps)\n",
    "X = data.drop(columns=['trip_duration', 'id', 'pickup_datetime'], errors='ignore')\n",
    "\n",
    "# Identify categorical columns\n",
    "categorical_cols = X.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Frequency encoding for high-cardinality categorical variables\n",
    "for col in categorical_cols:\n",
    "    freq_map = X[col].value_counts(normalize=True).to_dict()  # Map frequency of each category\n",
    "    X[col] = X[col].map(freq_map)\n",
    "\n",
    "# Replace NaN values (if any) generated due to mapping\n",
    "X = X.fillna(0)\n",
    "\n",
    "# Features and target variable\n",
    "y = data['trip_duration']\n",
    "\n",
    "# Ensure all columns are numeric\n",
    "X = X.select_dtypes(include=[float, int])  # Retain numeric columns\n",
    "\n",
    "# Scaling numeric features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Training set shape:\", X_train.shape)\n",
    "print(\"Testing set shape:\", X_test.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
